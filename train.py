# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17HKxjvGX2YpeFOH7YVIHhGWZq-0nMYDq
"""

import os, argparse, json
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from models.mtunet import MTUNet
from losses import DiceLoss, FocalLoss, UncertaintyWeightedMTL
from data import SliceDataset
from utils import dice_coefficient, f1_from_logits
from sklearn.model_selection import KFold
import numpy as np
from tqdm import tqdm
import timm

def build_items(img_dir, mask_dir, labels_json):
    # labels_json: map filename -> 6 dim one hot list
    labels = json.load(open(labels_json))
    items = []
    for name, cls in labels.items():
        img_path = os.path.join(img_dir, name)
        mname = name.replace(".png", "_mask.png")
        mask_path = os.path.join(mask_dir, mname)
        if os.path.exists(img_path) and os.path.exists(mask_path):
            items.append((img_path, mask_path, cls))
    return items

def main(args):
    items = build_items(args.img_dir, args.mask_dir, args.labels)
    kf = KFold(n_splits=args.folds, shuffle=True, random_state=42)

    for fold, (tr, va) in enumerate(kf.split(items), 1):
        if args.one_fold and fold != args.one_fold:
            continue
        train_set = SliceDataset([items[i] for i in tr], aug=True)
        val_set   = SliceDataset([items[i] for i in va], aug=False)
        train_loader = DataLoader(train_set, batch_size=args.bs, shuffle=True, num_workers=4, pin_memory=True)
        val_loader   = DataLoader(val_set, batch_size=args.bs, shuffle=False, num_workers=2)

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = MTUNet(in_ch=1, num_classes=6, seg_classes=1, encoder_name=args.encoder).to(device)

        ce_cls = nn.BCEWithLogitsLoss()
        dice_seg = DiceLoss()
        focal_seg = FocalLoss(gamma=2, alpha=0.25)
        mtl = UncertaintyWeightedMTL()

        opt = torch.optim.AdamW(list(model.parameters()) + list(mtl.parameters()), lr=args.lr, weight_decay=1e-4)
        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=args.epochs)

        best_f1 = 0.0
        wait = 0
        for epoch in range(1, args.epochs+1):
            model.train()
            for img, mask, cls in tqdm(train_loader, desc=f"fold {fold} epoch {epoch}"):
                img, mask, cls = img.to(device), mask.to(device), cls.to(device)
                logits_cls, logits_seg = model(img)

                loss_cls = ce_cls(logits_cls, cls)
                loss_seg = 0.5*dice_seg(logits_seg, mask) + 0.5*focal_seg(logits_seg, mask)
                loss = mtl(loss_cls, loss_seg)

                opt.zero_grad()
                loss.backward()
                opt.step()

            sch.step()

            # validation
            model.eval()
            with torch.no_grad():
                dsum, f1sum, n = 0.0, 0.0, 0
                for img, mask, cls in val_loader:
                    img, mask, cls = img.to(device), mask.to(device), cls.to(device)
                    logits_cls, logits_seg = model(img)
                    dsum += dice_coefficient(logits_seg, mask)
                    f1sum += f1_from_logits(logits_seg, mask)
                    n += 1
                dice = dsum / max(n,1)
                f1 = f1sum / max(n,1)

            print(f"[fold {fold}] epoch {epoch} dice {dice:.3f} f1 {f1:.3f}")
            if f1 > best_f1:
                best_f1 = f1
                wait = 0
                os.makedirs(args.out_dir, exist_ok=True)
                torch.save({"model": model.state_dict(),
                            "encoder": args.encoder}, os.path.join(args.out_dir, f"mtunet_fold{fold}.pt"))
            else:
                wait += 1
                if wait >= args.patience:
                    print("early stop")
                    break

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--img_dir", required=True)
    ap.add_argument("--mask_dir", required=True)
    ap.add_argument("--labels", required=True)  # json mapping
    ap.add_argument("--out_dir", default="weights")
    ap.add_argument("--bs", type=int, default=8)
    ap.add_argument("--epochs", type=int, default=80)
    ap.add_argument("--patience", type=int, default=40)
    ap.add_argument("--lr", type=float, default=1e-4)
    ap.add_argument("--folds", type=int, default=5)
    ap.add_argument("--one_fold", type=int, default=0)
    ap.add_argument("--encoder", default="tf_efficientnetv2_s")
    args = ap.parse_args()
    main(args)